{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Deep Learning\n",
    "## Project: Build a Digit Recognition Program\n",
    "\n",
    "In this notebook, a template is provided for you to implement your functionality in stages which is required to successfully complete this project. If additional code is required that cannot be included in the notebook, be sure that the Python code is successfully imported and included in your submission, if necessary. Sections that begin with **'Implementation'** in the header indicate where you should begin your implementation for your project. Note that some sections of implementation are optional, and will be marked with **'Optional'** in the header.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut. In addition, Markdown cells can be edited by typically double-clicking the cell to enter edit mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 1: Design and Test a Model Architecture\n",
    "Design and implement a deep learning model that learns to recognize sequences of digits. Train the model using synthetic data generated by concatenating character images from [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) or [MNIST](http://yann.lecun.com/exdb/mnist/). To produce a synthetic sequence of digits for testing, you can for example limit yourself to sequences up to five digits, and use five classifiers on top of your deep network. You would have to incorporate an additional ‘blank’ character to account for shorter number sequences.\n",
    "\n",
    "There are various aspects to consider when thinking about this problem:\n",
    "- Your model can be derived from a deep neural net or a convolutional network.\n",
    "- You could experiment sharing or not the weights between the softmax classifiers.\n",
    "- You can also use a recurrent network in your deep neural net to replace the classification layers and directly emit the sequence of digits one-at-a-time.\n",
    "\n",
    "Here is an example of a [published baseline model on this problem](http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42241.pdf). ([video](https://www.youtube.com/watch?v=vGPI_JvLoN0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 1280, Minibatch Loss= 23877.570312, Training Accuracy= 0.24219\n",
      "Iter 2560, Minibatch Loss= 12501.126953, Training Accuracy= 0.49219\n",
      "Iter 3840, Minibatch Loss= 7219.575195, Training Accuracy= 0.64062\n",
      "Iter 5120, Minibatch Loss= 3806.898926, Training Accuracy= 0.79688\n",
      "Iter 6400, Minibatch Loss= 3877.828369, Training Accuracy= 0.79688\n",
      "Iter 7680, Minibatch Loss= 8341.728516, Training Accuracy= 0.74219\n",
      "Iter 8960, Minibatch Loss= 2444.103027, Training Accuracy= 0.82812\n",
      "Iter 10240, Minibatch Loss= 2286.450195, Training Accuracy= 0.79688\n",
      "Iter 11520, Minibatch Loss= 1768.205078, Training Accuracy= 0.89844\n",
      "Iter 12800, Minibatch Loss= 2201.533203, Training Accuracy= 0.86719\n",
      "Iter 14080, Minibatch Loss= 1406.283936, Training Accuracy= 0.89844\n",
      "Iter 15360, Minibatch Loss= 1574.048706, Training Accuracy= 0.92188\n",
      "Iter 16640, Minibatch Loss= 2147.370605, Training Accuracy= 0.88281\n",
      "Iter 17920, Minibatch Loss= 1100.060059, Training Accuracy= 0.91406\n",
      "Iter 19200, Minibatch Loss= 1362.361450, Training Accuracy= 0.89844\n",
      "Iter 20480, Minibatch Loss= 374.882629, Training Accuracy= 0.96875\n",
      "Iter 21760, Minibatch Loss= 2726.570557, Training Accuracy= 0.88281\n",
      "Iter 23040, Minibatch Loss= 600.613770, Training Accuracy= 0.96875\n",
      "Iter 24320, Minibatch Loss= 1706.463623, Training Accuracy= 0.86719\n",
      "Iter 25600, Minibatch Loss= 1641.425781, Training Accuracy= 0.89062\n",
      "Iter 26880, Minibatch Loss= 1165.231079, Training Accuracy= 0.91406\n",
      "Iter 28160, Minibatch Loss= 647.042358, Training Accuracy= 0.92969\n",
      "Iter 29440, Minibatch Loss= 1274.554199, Training Accuracy= 0.92188\n",
      "Iter 30720, Minibatch Loss= 563.972412, Training Accuracy= 0.92188\n",
      "Iter 32000, Minibatch Loss= 569.471497, Training Accuracy= 0.95312\n",
      "Iter 33280, Minibatch Loss= 931.394226, Training Accuracy= 0.92188\n",
      "Iter 34560, Minibatch Loss= 439.105072, Training Accuracy= 0.95312\n",
      "Iter 35840, Minibatch Loss= 225.610992, Training Accuracy= 0.96875\n",
      "Iter 37120, Minibatch Loss= 553.529663, Training Accuracy= 0.92188\n",
      "Iter 38400, Minibatch Loss= 189.800385, Training Accuracy= 0.98438\n",
      "Iter 39680, Minibatch Loss= 155.750381, Training Accuracy= 0.97656\n",
      "Iter 40960, Minibatch Loss= 1863.873047, Training Accuracy= 0.91406\n",
      "Iter 42240, Minibatch Loss= 1116.727295, Training Accuracy= 0.92969\n",
      "Iter 43520, Minibatch Loss= 443.502014, Training Accuracy= 0.95312\n",
      "Iter 44800, Minibatch Loss= 336.019836, Training Accuracy= 0.96094\n",
      "Iter 46080, Minibatch Loss= 361.523224, Training Accuracy= 0.96094\n",
      "Iter 47360, Minibatch Loss= 669.919006, Training Accuracy= 0.93750\n",
      "Iter 48640, Minibatch Loss= 741.449036, Training Accuracy= 0.95312\n",
      "Iter 49920, Minibatch Loss= 967.182800, Training Accuracy= 0.89062\n",
      "Iter 51200, Minibatch Loss= 184.495132, Training Accuracy= 0.96094\n",
      "Iter 52480, Minibatch Loss= 261.627991, Training Accuracy= 0.95312\n",
      "Iter 53760, Minibatch Loss= 224.294983, Training Accuracy= 0.97656\n",
      "Iter 55040, Minibatch Loss= 635.519653, Training Accuracy= 0.96094\n",
      "Iter 56320, Minibatch Loss= 242.143051, Training Accuracy= 0.97656\n",
      "Iter 57600, Minibatch Loss= 88.560898, Training Accuracy= 0.98438\n",
      "Iter 58880, Minibatch Loss= 212.225296, Training Accuracy= 0.96094\n",
      "Iter 60160, Minibatch Loss= 1062.661133, Training Accuracy= 0.91406\n",
      "Iter 61440, Minibatch Loss= 430.013428, Training Accuracy= 0.95312\n",
      "Iter 62720, Minibatch Loss= 851.287476, Training Accuracy= 0.94531\n",
      "Iter 64000, Minibatch Loss= 170.122086, Training Accuracy= 0.97656\n",
      "Iter 65280, Minibatch Loss= 325.587341, Training Accuracy= 0.95312\n",
      "Iter 66560, Minibatch Loss= 573.790039, Training Accuracy= 0.92969\n",
      "Iter 67840, Minibatch Loss= 543.251343, Training Accuracy= 0.93750\n",
      "Iter 69120, Minibatch Loss= 927.141296, Training Accuracy= 0.94531\n",
      "Iter 70400, Minibatch Loss= 255.988281, Training Accuracy= 0.98438\n",
      "Iter 71680, Minibatch Loss= 448.825562, Training Accuracy= 0.93750\n",
      "Iter 72960, Minibatch Loss= 200.118561, Training Accuracy= 0.97656\n",
      "Iter 74240, Minibatch Loss= 613.600098, Training Accuracy= 0.96094\n",
      "Iter 75520, Minibatch Loss= 355.843781, Training Accuracy= 0.96094\n",
      "Iter 76800, Minibatch Loss= 182.142807, Training Accuracy= 0.96875\n",
      "Iter 78080, Minibatch Loss= 164.380219, Training Accuracy= 0.97656\n",
      "Iter 79360, Minibatch Loss= 307.070496, Training Accuracy= 0.96875\n",
      "Iter 80640, Minibatch Loss= 400.650513, Training Accuracy= 0.96875\n",
      "Iter 81920, Minibatch Loss= 132.378922, Training Accuracy= 0.97656\n",
      "Iter 83200, Minibatch Loss= 730.663818, Training Accuracy= 0.93750\n",
      "Iter 84480, Minibatch Loss= 421.880890, Training Accuracy= 0.96094\n",
      "Iter 85760, Minibatch Loss= 494.006500, Training Accuracy= 0.94531\n",
      "Iter 87040, Minibatch Loss= 515.491089, Training Accuracy= 0.96094\n",
      "Iter 88320, Minibatch Loss= 159.098465, Training Accuracy= 0.97656\n",
      "Iter 89600, Minibatch Loss= 13.411118, Training Accuracy= 0.99219\n",
      "Iter 90880, Minibatch Loss= 619.265991, Training Accuracy= 0.89844\n",
      "Iter 92160, Minibatch Loss= 389.793640, Training Accuracy= 0.92969\n",
      "Iter 93440, Minibatch Loss= 642.650513, Training Accuracy= 0.95312\n",
      "Iter 94720, Minibatch Loss= 217.884369, Training Accuracy= 0.93750\n",
      "Iter 96000, Minibatch Loss= 312.384979, Training Accuracy= 0.96094\n",
      "Iter 97280, Minibatch Loss= 317.178345, Training Accuracy= 0.96094\n",
      "Iter 98560, Minibatch Loss= 196.457947, Training Accuracy= 0.97656\n",
      "Iter 99840, Minibatch Loss= 94.194344, Training Accuracy= 0.97656\n",
      "Iter 101120, Minibatch Loss= 142.283310, Training Accuracy= 0.97656\n",
      "Iter 102400, Minibatch Loss= 666.620056, Training Accuracy= 0.94531\n",
      "Iter 103680, Minibatch Loss= 357.182068, Training Accuracy= 0.94531\n",
      "Iter 104960, Minibatch Loss= 429.722717, Training Accuracy= 0.95312\n",
      "Iter 106240, Minibatch Loss= 336.273926, Training Accuracy= 0.96875\n",
      "Iter 107520, Minibatch Loss= 137.541321, Training Accuracy= 0.97656\n",
      "Iter 108800, Minibatch Loss= 328.368225, Training Accuracy= 0.94531\n",
      "Iter 110080, Minibatch Loss= 29.988052, Training Accuracy= 0.98438\n",
      "Iter 111360, Minibatch Loss= 82.906769, Training Accuracy= 0.96875\n",
      "Iter 112640, Minibatch Loss= 78.681343, Training Accuracy= 0.98438\n",
      "Iter 113920, Minibatch Loss= 245.710159, Training Accuracy= 0.95312\n",
      "Iter 115200, Minibatch Loss= 504.800232, Training Accuracy= 0.95312\n",
      "Iter 116480, Minibatch Loss= 0.834259, Training Accuracy= 0.99219\n",
      "Iter 117760, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 119040, Minibatch Loss= 40.592754, Training Accuracy= 0.98438\n",
      "Iter 120320, Minibatch Loss= 148.173111, Training Accuracy= 0.97656\n",
      "Iter 121600, Minibatch Loss= 330.648376, Training Accuracy= 0.94531\n",
      "Iter 122880, Minibatch Loss= 12.716415, Training Accuracy= 0.98438\n",
      "Iter 124160, Minibatch Loss= 228.469727, Training Accuracy= 0.97656\n",
      "Iter 125440, Minibatch Loss= 437.459320, Training Accuracy= 0.97656\n",
      "Iter 126720, Minibatch Loss= 291.456360, Training Accuracy= 0.96875\n",
      "Iter 128000, Minibatch Loss= 8.716789, Training Accuracy= 0.99219\n",
      "Iter 129280, Minibatch Loss= 430.283386, Training Accuracy= 0.96094\n",
      "Iter 130560, Minibatch Loss= 385.784363, Training Accuracy= 0.95312\n",
      "Iter 131840, Minibatch Loss= 532.149048, Training Accuracy= 0.92969\n",
      "Iter 133120, Minibatch Loss= 55.178047, Training Accuracy= 0.96094\n",
      "Iter 134400, Minibatch Loss= 156.155731, Training Accuracy= 0.96875\n",
      "Iter 135680, Minibatch Loss= 15.559296, Training Accuracy= 0.99219\n",
      "Iter 136960, Minibatch Loss= 104.817200, Training Accuracy= 0.96875\n",
      "Iter 138240, Minibatch Loss= 349.523193, Training Accuracy= 0.94531\n",
      "Iter 139520, Minibatch Loss= 96.460106, Training Accuracy= 0.97656\n",
      "Iter 140800, Minibatch Loss= 154.556152, Training Accuracy= 0.96875\n",
      "Iter 142080, Minibatch Loss= 531.839355, Training Accuracy= 0.92969\n",
      "Iter 143360, Minibatch Loss= 214.002777, Training Accuracy= 0.96875\n",
      "Iter 144640, Minibatch Loss= 43.932301, Training Accuracy= 0.96875\n",
      "Iter 145920, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 147200, Minibatch Loss= 136.481995, Training Accuracy= 0.98438\n",
      "Iter 148480, Minibatch Loss= 268.960907, Training Accuracy= 0.96094\n",
      "Iter 149760, Minibatch Loss= 93.385025, Training Accuracy= 0.96875\n",
      "Iter 151040, Minibatch Loss= 207.153763, Training Accuracy= 0.96875\n",
      "Iter 152320, Minibatch Loss= 261.225220, Training Accuracy= 0.96094\n",
      "Iter 153600, Minibatch Loss= 233.035278, Training Accuracy= 0.96094\n",
      "Iter 154880, Minibatch Loss= 264.628387, Training Accuracy= 0.96875\n",
      "Iter 156160, Minibatch Loss= 161.382965, Training Accuracy= 0.99219\n",
      "Iter 157440, Minibatch Loss= 335.370239, Training Accuracy= 0.93750\n",
      "Iter 158720, Minibatch Loss= 556.210876, Training Accuracy= 0.93750\n",
      "Iter 160000, Minibatch Loss= 84.311432, Training Accuracy= 0.96094\n",
      "Iter 161280, Minibatch Loss= 157.220367, Training Accuracy= 0.96094\n",
      "Iter 162560, Minibatch Loss= 412.977600, Training Accuracy= 0.93750\n",
      "Iter 163840, Minibatch Loss= 326.290649, Training Accuracy= 0.96875\n",
      "Iter 165120, Minibatch Loss= 193.982086, Training Accuracy= 0.98438\n",
      "Iter 166400, Minibatch Loss= 4.839766, Training Accuracy= 0.98438\n",
      "Iter 167680, Minibatch Loss= 229.721756, Training Accuracy= 0.98438\n",
      "Iter 168960, Minibatch Loss= 109.587166, Training Accuracy= 0.96875\n",
      "Iter 170240, Minibatch Loss= 140.776825, Training Accuracy= 0.96094\n",
      "Iter 171520, Minibatch Loss= 140.793671, Training Accuracy= 0.96875\n",
      "Iter 172800, Minibatch Loss= 104.063278, Training Accuracy= 0.98438\n",
      "Iter 174080, Minibatch Loss= 30.857857, Training Accuracy= 0.99219\n",
      "Iter 175360, Minibatch Loss= 6.494308, Training Accuracy= 0.99219\n",
      "Iter 176640, Minibatch Loss= 37.347389, Training Accuracy= 0.97656\n",
      "Iter 177920, Minibatch Loss= 373.542969, Training Accuracy= 0.95312\n",
      "Iter 179200, Minibatch Loss= 354.634277, Training Accuracy= 0.96875\n",
      "Iter 180480, Minibatch Loss= 156.576721, Training Accuracy= 0.96094\n",
      "Iter 181760, Minibatch Loss= 151.891296, Training Accuracy= 0.97656\n",
      "Iter 183040, Minibatch Loss= 404.225464, Training Accuracy= 0.96094\n",
      "Iter 184320, Minibatch Loss= 156.511261, Training Accuracy= 0.97656\n",
      "Iter 185600, Minibatch Loss= 100.156097, Training Accuracy= 0.96094\n",
      "Iter 186880, Minibatch Loss= 20.742258, Training Accuracy= 0.99219\n",
      "Iter 188160, Minibatch Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Iter 189440, Minibatch Loss= 158.392883, Training Accuracy= 0.96875\n",
      "Iter 190720, Minibatch Loss= 138.432983, Training Accuracy= 0.98438\n",
      "Iter 192000, Minibatch Loss= 210.129395, Training Accuracy= 0.96875\n",
      "Iter 193280, Minibatch Loss= 120.052727, Training Accuracy= 0.96875\n",
      "Iter 194560, Minibatch Loss= 177.574585, Training Accuracy= 0.95312\n",
      "Iter 195840, Minibatch Loss= 35.857437, Training Accuracy= 0.99219\n",
      "Iter 197120, Minibatch Loss= 102.974464, Training Accuracy= 0.98438\n",
      "Iter 198400, Minibatch Loss= 99.880035, Training Accuracy= 0.95312\n",
      "Iter 199680, Minibatch Loss= 72.245926, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.976562\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tf.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "def make_sequence(images, labels, max_length=5):\n",
    "    length = np.floor((max_length+1) * np.random.rand())\n",
    "    position = np.ceil((max_length - length)*np.random.rand())\n",
    "    sequence = np.array([])\n",
    "    sequence_value = ''\n",
    "    for i in range(position):\n",
    "        sequence = np.cancatenate((sequence, np.zeros(28*28)))\n",
    "    for i in range(length):\n",
    "        image = images[-1]\n",
    "        images = np.delete(images, -1)\n",
    "        label = labels[-1]\n",
    "        labels = np.delete(labels, -1)\n",
    "        sequence = np.cancatenate((sequence, image))\n",
    "        del image_indices[-1]\n",
    "        sequence_value += str(label)\n",
    "    for i in range(length - position):\n",
    "        sequence = np.cancatenate((sequence, np.zeros(28*28)))\n",
    "    sequence_value = int(sequence_value)\n",
    "    sequence_label = np.zeros(100000)\n",
    "    sequence_label[sequence_value] = 1.\n",
    "    return sequence, sequence_label\n",
    "    \n",
    "def cancatenate_images(images, labels, sequence_length=5):\n",
    "    image_indices = random.shuffle(range(len(images)))\n",
    "    iterations = np.floor(len(images))/float(sequence_length)\n",
    "    sequences = np.array([])\n",
    "    labels = np.array([])\n",
    "    for i in range(iterations):\n",
    "        sequence, label = make_sequence(images, labels, sequence_length)\n",
    "        sequences.append(sequence)\n",
    "        labels.append(label)\n",
    "    return sequences, labels\n",
    "        \n",
    "        \n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 200000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 * 5 # MNIST data input (img shape: 28*28)\n",
    "n_classes = \n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)\n",
    "\n",
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Reshape input picture\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Apply Dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output, class prediction\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        sequences, labels = cancatenate_images(batch_x, batch_y)\n",
    "        \n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: sequences, y: labels,\n",
    "                                       keep_prob: dropout})\n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: sequences,\n",
    "                                                              y: labels,\n",
    "                                                              keep_prob: 1.})\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 256 mnist test images\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: mnist.test.images[:256],\n",
    "                                      y: mnist.test.labels[:256],\n",
    "                                      keep_prob: 1.}))\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "_What approach did you take in coming up with a solution to this problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "I originally considered using an RNN, but I decided this did not make sense for a sequence of numbers. RNNs are useful when a sequence of inputs affects the probability of following inputs, such as in machine translation or speech recognition.\n",
    "\n",
    "In the case of number sequences, this is no\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "_What does your final architecture look like? (Type of model, layers, sizes, connectivity, etc.)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "_How did you train your model? How did you generate your synthetic dataset?_ Include examples of images from the synthetic data you constructed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 2: Train a Model on a Realistic Dataset\n",
    "Once you have settled on a good architecture, you can train your model on real data. In particular, the [Street View House Numbers (SVHN)](http://ufldl.stanford.edu/housenumbers/) dataset is a good large-scale dataset collected from house numbers in Google Street View. Training on this more challenging dataset, where the digits are not neatly lined-up and have various skews, fonts and colors, likely means you have to do some hyperparameter exploration to perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "_Describe how you set up the training and testing data for your model. How does the model perform on a realistic dataset?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named DownloadAndPickle",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9d45996e3212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mDownloadAndPickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_download\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDownloadAndPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://ufldl.stanford.edu/housenumbers/train.tar.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_download\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_download\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDownloadAndPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://ufldl.stanford.edu/housenumbers/test.tar.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named DownloadAndPickle"
     ]
    }
   ],
   "source": [
    "import DownloadAndPickle\n",
    "\n",
    "train_download = DownloadAndPickle('http://ufldl.stanford.edu/housenumbers', 'train.tar.gz')\n",
    "train_download.ensure(, 73257)\n",
    "test_download = DownloadAndPickle('http://ufldl.stanford.edu/housenumbers', 'test.tar.gz')\n",
    "test_download.maybe_download(, 26032)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "_What changes did you have to make, if any, to achieve \"good\" results? Were there any options you explored that made the results worse?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "_What were your initial and final results with testing on a realistic dataset? Do you believe your model is doing a good enough job at classifying numbers correctly?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Step 3: Test a Model on Newly-Captured Images\n",
    "\n",
    "Take several pictures of numbers that you find around you (at least five), and run them through your classifier on your computer to produce example results. Alternatively (optionally), you can try using OpenCV / SimpleCV / Pygame to capture live images from a webcam and run those through your classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "_Choose five candidate images of numbers you took from around you and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Leave blank if you did not complete this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Step 4: Explore an Improvement for a Model\n",
    "\n",
    "There are many things you can do once you have the basic classifier in place. One example would be to also localize where the numbers are on the image. The SVHN dataset provides bounding boxes that you can tune to train a localizer. Train a regression loss to the coordinates of the bounding box, and then test it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "_How well does your model localize numbers on the testing set from the realistic dataset? Do your classification results change at all with localization included?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "_Test the localization function on the images you captured in **Step 3**. Does the model accurately calculate a bounding box for the numbers in the images you found? If you did not use a graphical interface, you may need to investigate the bounding boxes by hand._ Provide an example of the localization created on a captured image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Optional Step 5: Build an Application or Program for a Model\n",
    "Take your project one step further. If you're interested, look to build an Android application or even a more robust Python program that can interface with input images and display the classified numbers and even the bounding boxes. You can for example try to build an augmented reality app by overlaying your answer on the image like the [Word Lens](https://en.wikipedia.org/wiki/Word_Lens) app does.\n",
    "\n",
    "Loading a TensorFlow model into a camera app on Android is demonstrated in the [TensorFlow Android demo app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android), which you can simply modify.\n",
    "\n",
    "If you decide to explore this optional route, be sure to document your interface and implementation, along with significant results you find. You can see the additional rubric items that you could be evaluated on by [following this link](https://review.udacity.com/#!/rubrics/413/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your optional code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "Provide additional documentation sufficient for detailing the implementation of the Android application or Python program for visualizing the classification of numbers in images. It should be clear how the program or application works. Demonstrations should be provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write your documentation here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
    "**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
